{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f904cc-efd4-4f39-92cc-323ad8230633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import os\n",
    "import videoto3d\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60e2b1b-6e08-4593-93b2-f9ed0c604142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 32, 32, 10, 3], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"conv3d_input\"}}, {\"class_name\": \"Conv3D\", \"config\": {\"name\": \"conv3d\", \"trainable\": true, \"batch_input_shape\": [null, 32, 32, 10, 3], \"dtype\": \"float32\", \"filters\": 32, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"groups\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"relu\"}}, {\"class_name\": \"Conv3D\", \"config\": {\"name\": \"conv3d_1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 32, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"groups\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation_1\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"softmax\"}}, {\"class_name\": \"MaxPooling3D\", \"config\": {\"name\": \"max_pooling3d\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [3, 3, 3], \"padding\": \"same\", \"strides\": [3, 3, 3], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.25, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Conv3D\", \"config\": {\"name\": \"conv3d_2\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 64, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"groups\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation_2\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"relu\"}}, {\"class_name\": \"Conv3D\", \"config\": {\"name\": \"conv3d_3\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 64, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"groups\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation_3\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"softmax\"}}, {\"class_name\": \"MaxPooling3D\", \"config\": {\"name\": \"max_pooling3d_1\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [3, 3, 3], \"padding\": \"same\", \"strides\": [3, 3, 3], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_1\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.25, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 512, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_2\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.5, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 13, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.6.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file = open('3dcnnmodel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "loaded_model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf1fd01-d3f8-4090-9294-f0c2728dd08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1039d515-6a17-4fb0-a3e3-bb82d6b9850f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x293e3758cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f570b75-9325-4686-84b0-7f1ff12781d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2938c220f10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.load_weights(\"3dcnnmodel-gpu.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669704c1-ccd1-42ef-a959-73b7b4059a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata(video_dir, vid3d, nclass, result_dir, color=False, skip=True):\n",
    "    \n",
    "    files = os.listdir(video_dir)    \n",
    "    X = []\n",
    "    labels = []\n",
    "    labellist = []\n",
    "    Y = []\n",
    "    pbar = tqdm(total=len(files))\n",
    "\n",
    "    for filename in files:\n",
    "    \n",
    "        pbar.update(1)\n",
    "        \n",
    "        if filename == '.DS_Store':\n",
    "            continue\n",
    "        \n",
    "        name = os.path.join(video_dir, filename)\n",
    "        x = 0\n",
    "        for v_files in os.listdir(name):\n",
    "\n",
    "            v_file_path = os.path.join(name, v_files)\n",
    "\n",
    "            label = vid3d.get_UCF_classname(filename)\n",
    "            \n",
    "            \n",
    "            \n",
    "            video_array = vid3d.video3d(v_file_path, color=color, skip=skip)\n",
    "            if video_array is None:\n",
    "                print(f\"Skipping video {v_file_path} due to error.\")\n",
    "                continue\n",
    "            X.append(video_array)\n",
    "            if label not in labellist:\n",
    "                \n",
    "                if len(labellist) >= nclass:\n",
    "                    continue\n",
    "\n",
    "                labellist.append(label)\n",
    "            \n",
    "            labels.append(label)\n",
    "        \n",
    "    pbar.close()\n",
    "\n",
    "    for num, label in enumerate(labellist):\n",
    "        for i in range(len(labels)):\n",
    "            if label == labels[i]:\n",
    "                labels[i] = num\n",
    "    if color:\n",
    "        print(\"Shape of X before transposition:\", np.array(X).shape)\n",
    "        return np.array(X).transpose((0, 2, 3, 4, 1)), labels\n",
    "    else:\n",
    "        print(\"Shape of X before transposition:\", np.array(X).shape)\n",
    "        return np.array(X).transpose((0, 2, 3, 1)), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "120378fe-2fc9-401f-92b5-3a965889fe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▊                                                                      | 2/13 [00:03<00:19,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████▏                                                               | 3/13 [00:12<00:47,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▌                                                         | 4/13 [00:26<01:13,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▉                                                   | 5/13 [00:27<00:46,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████▎                                            | 6/13 [00:29<00:30,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████▋                                      | 7/13 [00:29<00:18,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████                                | 8/13 [00:30<00:12,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|█████████████████████████████████████████████████████████▍                         | 9/13 [00:32<00:08,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████████████                   | 10/13 [00:57<00:27,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Warning: Empty or invalid frame encountered at index 1 in video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\sitting\\okutama_1.2.1_Sitting_77.mp4\n",
      "Skipping video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\sitting\\okutama_1.2.1_Sitting_77.mp4 due to error.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████▍            | 11/13 [01:25<00:29, 14.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████████▋      | 12/13 [01:31<00:12, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Warning: Empty or invalid frame encountered at index 0 in video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\vandalizing\\uccrime_Vandalism035_x264.mp4\n",
      "Skipping video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\vandalizing\\uccrime_Vandalism035_x264.mp4 due to error.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [01:41<00:00, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Warning: Empty or invalid frame encountered at index 0 in video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\walking\\casia_angleview_p07_crouch_a1.mp4\n",
      "Skipping video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\walking\\casia_angleview_p07_crouch_a1.mp4 due to error.\n",
      "\n",
      "Warning: Empty or invalid frame encountered at index 0 in video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\walking\\casia_angleview_p07_wonder_a1.mp4\n",
      "Skipping video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\walking\\casia_angleview_p07_wonder_a1.mp4 due to error.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Warning: Empty or invalid frame encountered at index 0 in video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\walking\\casia_topdownview_p02_wonder_a1.mp4\n",
      "Skipping video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\walking\\casia_topdownview_p02_wonder_a1.mp4 due to error.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Warning: Empty or invalid frame encountered at index 0 in video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\walking\\ucarg_person07_02_ground_carrying.mp4\n",
      "Skipping video C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid\\walking\\ucarg_person07_02_ground_carrying.mp4 due to error.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [03:16<00:00, 15.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Shape of X before transposition: (552, 10, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 16957440 into shape (552,32,32,10,10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m vid3d \u001b[38;5;241m=\u001b[39m videoto3d\u001b[38;5;241m.\u001b[39mVideoto3D(img_rows, img_cols, frames)\n\u001b[0;32m      3\u001b[0m x, y \u001b[38;5;241m=\u001b[39m loaddata(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMY PC\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m3d-cnn-action-recognition\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msphar\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, vid3d, \u001b[38;5;241m13\u001b[39m,\n\u001b[0;32m      4\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m X \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], img_rows, img_cols, frames, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      6\u001b[0m Y \u001b[38;5;241m=\u001b[39m np_utils\u001b[38;5;241m.\u001b[39mto_categorical(y, nb_classes)\n\u001b[0;32m      7\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 16957440 into shape (552,32,32,10,10)"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols, frames = 32, 32, 10\n",
    "vid3d = videoto3d.Videoto3D(img_rows, img_cols, frames)\n",
    "x, y = loaddata(r'C:\\Users\\MY PC\\3d-cnn-action-recognition\\sphar\\valid', vid3d, 13,\n",
    "                        \"validation\", True, True)\n",
    "X = x.reshape((x.shape[0], img_rows, img_cols, frames, 10))\n",
    "Y = np_utils.to_categorical(y, nb_classes)\n",
    "X = X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf13081-c46e-4c37-94ae-261115b47884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
