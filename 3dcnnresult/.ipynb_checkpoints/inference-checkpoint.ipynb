{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6294c8c8-e590-4ba8-acc4-84eb87fdb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import os\n",
    "import videoto3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc40689-da14-4f18-8b9f-ac95a0dc86df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 32, 32, 10, 3], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"conv3d_input\"}}, {\"class_name\": \"Conv3D\", \"config\": {\"name\": \"conv3d\", \"trainable\": true, \"batch_input_shape\": [null, 32, 32, 10, 3], \"dtype\": \"float32\", \"filters\": 32, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"groups\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"relu\"}}, {\"class_name\": \"Conv3D\", \"config\": {\"name\": \"conv3d_1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 32, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"groups\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation_1\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"softmax\"}}, {\"class_name\": \"MaxPooling3D\", \"config\": {\"name\": \"max_pooling3d\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [3, 3, 3], \"padding\": \"same\", \"strides\": [3, 3, 3], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.25, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Conv3D\", \"config\": {\"name\": \"conv3d_2\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 64, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"groups\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation_2\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"relu\"}}, {\"class_name\": \"Conv3D\", \"config\": {\"name\": \"conv3d_3\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 64, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"groups\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation_3\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"softmax\"}}, {\"class_name\": \"MaxPooling3D\", \"config\": {\"name\": \"max_pooling3d_1\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [3, 3, 3], \"padding\": \"same\", \"strides\": [3, 3, 3], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_1\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.25, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 512, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_2\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.5, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 13, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.6.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file = open('3dcnnmodel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "loaded_model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79008c30-4cda-4e44-ad52-29bce6e4c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6aac5f-5192-4b1c-9738-acfddcb5e7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x11e6744d650>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7ebd28-9573-426e-b6e9-385efcd50158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x11e66c09c50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.load_weights(\"3dcnnmodel-gpu.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "676f1077-cd77-40d7-8d5d-3c1010884a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check of weigths of biases of first layer\n",
    "#weights, biases = loaded_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "210ed90a-2a87-4599-ab6f-d85fd22e7d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Empty or invalid frame encountered at index 0 in video 3d-cnn-action-recognition/sphar/valid/running/ucarg_person09_04_rooftop_jogging.mp4\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Video Corrupted Upload another Video",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m Video Corrupted Upload another Video\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols, frames = 32, 32, 10\n",
    "filepath = '3d-cnn-action-recognition/sphar/valid/running/ucaerial_actions1_Running_0_0.mp4'\n",
    "vid3d = videoto3d.Videoto3D(img_rows, img_cols, frames)\n",
    "x = []\n",
    "video_array = vid3d.video3d(filepath, color=True, skip=True)\n",
    "if video_array is None:\n",
    "    raise SystemExit(\"Video Corrupted Upload another Video\")\n",
    "x.append(video_array)\n",
    "x_arr = np.array(x).transpose((0, 2, 3, 4, 1))\n",
    "X = x_arr.reshape((x_arr.shape[0], img_rows, img_cols, frames, 3))\n",
    "X = X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4cc811-e671-4d5e-8612-93f21ac6e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"carcrash\", \"falling\", \"hitting\", \"igniting\", \"kicking\", \n",
    "    \"luggage\", \"murdering\", \"panicking\", \"running\", \"sitting\", \n",
    "    \"stealing\", \"vandalizing\", \"walking\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3437c3c-e6f5-4eb8-ba1f-50c23f533193",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f820a6e-d7a1-403c-be87-e58c434a2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_indices = np.argsort(prediction[0])[::-1][:5]\n",
    "top_5_classes = [classes[i] for i in top_5_indices]\n",
    "top_5_probabilities = [prediction[0][i] for i in top_5_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b5205d4-1648-4724-a561-eb84b3faf911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Predictions:\n",
      "1. Class: vandalizing, Probability: 0.4065\n",
      "2. Class: walking, Probability: 0.2502\n",
      "3. Class: hitting, Probability: 0.1808\n",
      "4. Class: running, Probability: 0.1607\n",
      "5. Class: sitting, Probability: 0.0010\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Predictions:\")\n",
    "for i, (class_name, probability) in enumerate(zip(top_5_classes, top_5_probabilities), 1):\n",
    "    print(f\"{i}. Class: {class_name}, Probability: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e532f2-062f-41e0-a6f5-5b0504c62f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
